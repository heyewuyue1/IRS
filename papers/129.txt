DmyT: Dummy Triplet Loss for Deepfake Detection
Nicolas Beuve, Wassim Hamidouche, Olivier Deforges
ADGD '21: Proceedings of the 1st Workshop on Synthetic Multimedia - Audiovisual Deepfake Generation and Detection
20 October 2021
Recent progress in deep learning-based image generation has madeit easier to create convincing fake videos called deepfakes. Whilethe benefits of such technology are undeniable, it can also be usedas realistic fake news support for mass disinformation. In this con-test, different detectors were proposed, many of them use a CNN asa backbone model and the binary cross-entropy as a loss function.Some more recent approaches applied a triplet loss with semi-hardtriplets. In this paper, we investigate the use of triplet loss with fixedpositive and negative vectors as a replacement for semi-hard triplets.This loss, called dummy triplet loss (DmyT), follows the concept ofthe triplet loss but requires less computation, as the triplets are fixed.It also doesn't rely on a linear classifier for prediction. We haveassessed the performance of the proposed loss with four backbonenetworks, including two of the most popular CNNs in the Deepfakerealm, Xception and EfficientNet, alongside two visual transformernetworks, ViT and CaiT. Our loss function shows competitive re-sults on FaceForensics++ dataset compared to triplet loss with semi-hard triplets while being less computationally intensive. The sourcecode of DmyT is available at https://github.com/beuve/DmyT.
https://dl.acm.org/doi/10.1145/3476099.3484316
