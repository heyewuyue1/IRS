Language Representation Models for Music Genre Classification Using Lyrics
Hasan Akalp, Enes Furkan Cigdem, Seyma Yilmaz, Necva Bolucu, Burcu Can
ISEEIE 2021: 2021 International Symposium on Electrical, Electronics and Information Engineering
20 July 2021
There are various genres of music available in every period and field of human life. Every music genre represents a set of shared conventions. Today people have the opportunity to listen to any genre of music they want using various music platforms. However, with the increasing number of music genres, the management of these platforms becomes difficult. Language representation models such as BERT, DistilBERT have been proven to be useful in learning universal language representations. Such language representation models have achieved amazing results in many language understanding tasks. In this study, we apply language representation models for music genre classification using song lyrics. We examine whether language representation models are better than traditional deep learning models for music genre classification by comparing results and computation times. Experimental results show that BERT outperforms other models on one-label and multi-label classification with accuracy of 77.63% and 71.29% respectively. On the other hand, considering the time taken for one epoch, BERT runs 4 times faster than DistilBERT.
https://dl.acm.org/doi/10.1145/3459104.3459171
