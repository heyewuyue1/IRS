Distance and Direction Based Deep Discriminant Metric Learning for Kinship Verification
Xiaoke Zhu, Changlong Li, Xiaopan Chen, Xinyu Zhang, Xiao-Yuan Jing
ACM Transactions on Multimedia Computing, Communications, and Applications
23 January 2023
Image-based kinship verification is an important task in computer vision and has many applications in practice, such as missing children search and family album construction, among others. Due to the differences in age, gender, expression and appearance, there usually exists a large discrepancy between the facial images of parent and child. This makes kinship verification a challenging task. In this article, we propose a Distance and Direction Based Deep Discriminant Metric Learning (D 4 ML) approach for kinship verification. The basic idea of D 4 ML is to make full use of the discriminant information contained in the facial images of parent and child such that the network can learn more a discriminating distance metric. Specifically, D 4 ML learns the metric by utilizing the discriminant information from two perspectives: distance-based perspective and direction-based perspective. From the distance-based perspective, the designed loss function is used to minimize the distance between images having kinship and maximize the distance between images without kinship. In practice, the gender difference and large age gap may significantly increase the distance between facial images of parent and child. Therefore, learning the metric only from a distance-based perspective is insufficient. Considering that two vectors with a large distance may appear with high similarity in direction, D 4 ML also employs the direction-based loss function in the training process. Both kinds of loss function work together to improve the discriminability of the learned metric. Experimental results on four small size publicly available datasets demonstrate the effectiveness of our approach. Source code of our approach can be found at https://github.com/lclhenu/D4ML .
https://dl.acm.org/doi/10.1145/3531014
