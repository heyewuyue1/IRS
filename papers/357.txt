Squeeze-and-Excitation network-Based Radar Object Detection With Weighted Location Fusion
Pengliang Sun, Xuetong Niu, Pengfei Sun, Kele Xu
ICMR '21: Proceedings of the 2021 International Conference on Multimedia Retrieval
01 September 2021
Radar object detection refers to identify objects from radar data, and the topic has received increasing interest during the last years, due to the appealing property of radar imaging and evident applications. However, the detection performance heavily relied on semantic information extraction, which is a great challenge in practical settings. Moreover, although remarkable progress has been made, most previous attempts are restrained from the essentially limited property of the employed single modality. Inspired by the recent success of cross-modality deep learning, we propose a novel cross-modality deep learning framework for the radar object detection task using the Squeeze-and-Excitation network, aiming to provide more powerful feature representation. Moreover, a novel noisy detection approach is also explored in our study, to increase the model's ability to handle with noise. Finally, a novel weighted location fusion strategy is introduced in our framework, to improve the detection performance further. To empirically investigate the effectiveness of the proposed framework, we conduct extensive experiments on the 2021 ICMR ROD challenge. The obtained results suggest that our framework outperforms related approaches. Our method ranks as the 3rd place on the final leaderboard, with an average precision (AP) percentage of 76.1. Models and codes are available at https://github.com/sunpengliang/modelConfusion.
https://dl.acm.org/doi/10.1145/3460426.3463654
